{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing template\n",
    "  \n",
    "    \n",
    "Here we import our essential libraries  \n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "### What to do with missing data?  \n",
    "- Some options are to remove the line of data completely.    \n",
    "- Another common solution is to fill the missing value with the average of the data. Good package to use for this is `sklearn.preprocessing`  \n",
    "\n",
    "### Encoding Categorical Data  \n",
    "To do this we can use the `sklearn.preprocessing import LabelEncoder` package  \n",
    "When adjusting, we have to remember we need the columns to represent numerical data, when changing this we need encode. However we don't want to confuse our ML model by it thinking that one label is greater than another, therefore we use `OneHotEncoder`. Using `OneHotEncoder` we will replace the target column with multiple columns responding to the category label. Each column will be filled with 0s and 1s, thus eliminating competing values attributiion, a.k.a *dummy variables*.  \n",
    "  \n",
    "### Spliting Dataset  \n",
    "Why do we split the data? To avoid **overfitting**. So we make a training set and a test set. Convention is to use 20% for test.  \n",
    "  \n",
    "### Feature Scaling\n",
    "- A lot of ML models are based on Euclidean distance.  \n",
    "- When data variables have a large range, the Euclidean distance may be skewed by a dominating value. To solve this problem, we will **feature scale**.\n",
    "- Feature Scaling: \n",
    "  - Standaridzation:  \n",
    "  <img src=\"standardization.png\" alt=\"standard\">  \n",
    "  - Normalization:  \n",
    "  <img src=\"normalization.png\" alt=\"normal\">  \n",
    "  \n",
    "- Do we need to sclae dummy variables? Depends on data. Depends on how we need to translate data.  \n",
    "- Do we need to feature scale y? Not here, our data is a classification problem. Often regression needs feature scaling because of the large range. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
